{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96490deb",
   "metadata": {},
   "source": [
    "### Outline\n",
    "\n",
    "- *Load the CIFAR-10 Dataset*\n",
    "- *Dataset Preprocessing*\n",
    "- *Dataset and Training Configuration Parameters*\n",
    "- *CNN Model Implementation in Keras*\n",
    "- *Adding Dropout to the Model*\n",
    "- *Saving and Loading Models*\n",
    "- *Model Evaluation*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility in TensorFlow\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a4657",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the CIFAR-10 dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "dataset = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c16ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36074a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c4ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50000 training images, each of size 32x32 with 3 color channels\n",
    "# 32 The hight and width of each image in pixels\n",
    "# 3 The number of color channels (RGB)\n",
    "\n",
    "dataset[0][0].shape  # (50000, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32: The hight of the image in pixels\n",
    "# 32: The width of the image in pixels\n",
    "# 3: The number of color channels (RGB)\n",
    "\n",
    "dataset[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e51fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the number of channels in the first image\n",
    "data = dataset[0][0][0]  # First image in the training set\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "# Scatter Plot (for sparse data or voxels)\n",
    "fig = plt.figure(figsize=(30, 10))\n",
    "\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "x, y, z = np.where(data > 0.5)  # Show points above threshold\n",
    "ax1.scatter(x, y, z, c=data[x, y, z], cmap='viridis', marker='o')\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_zlabel('Z')\n",
    "ax1.set_title('3D Scatter Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training and testing data from the dataset\n",
    "(X_train, y_train), (X_test, y_test) = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CIFAR-10 dataset consists of 50,000 training images and 10,000 test images\n",
    "# with 10 classes.\n",
    "print(f\"X_train Shape: {X_train.shape}\")\n",
    "print(f\"y_train Shape: {y_train.shape}\")\n",
    "print(f\"X_test Shape: {X_test.shape}\")\n",
    "print(f\"y_test Shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc907f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise sample images from the dataset\n",
    "\n",
    "plt.figure(figsize=(18, 9))\n",
    "\n",
    "num_rows = 4\n",
    "num_cols = 8\n",
    "\n",
    "# plot each of the images in th ebatch and the assoficated label\n",
    "for i in range(num_rows*num_cols):\n",
    "    plt.subplot(num_rows, num_cols, i+1)\n",
    "    plt.imshow(X_train[i].astype(\"uint8\"))\n",
    "    plt.title(f\"Label: {y_train[i][0]}\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca8db1",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89805239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the labels from integer to categorical data.\n",
    "print(\"Original (integer) label for the first training sample:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a440a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deeee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341da52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After conversion to categorical one-hot encoded labels: ', y_train[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0109a04",
   "metadata": {},
   "source": [
    "### NOTE: \n",
    "\n",
    "- **The @dataclass(frozen=True) decorator, is a clean and standard way to define a Configuration Class for a Machine Learning or Deep Learning training script.**\n",
    "\n",
    "- **The primary use of this structure is to centralize, organize, and manage the hyperparameters used to train a machine learning model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87073f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset and Training Configuration Parameters`\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DatasetConfig:\n",
    "    NUM_CLASSES: int = 10\n",
    "    IMAGE_HEIGHT: int = 32\n",
    "    IMAGE_WIDTH: int = 32\n",
    "    IMAGE_CHANNELS: int = 3\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    BATCH_SIZE: int = 64\n",
    "    EPOCHS: int = 25\n",
    "    LEARNING_RATE: float = 0.001\n",
    "    VALIDATION_SPLIT: float = 0.3  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec323dbd",
   "metadata": {},
   "source": [
    "### CNN Model Implementation in Keras\n",
    "\n",
    "- **Build/Define a network model using predefined layers in Keras.**\n",
    "- **Compile the model with model.compile()**\n",
    "- **Train the model with model.fit()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model using the sequential API\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "\n",
    "\n",
    "# First Conv Layer (32 filters, 3x3 kernel, ReLU activation, input shape)\n",
    "input_shape=(32, 32, 3)\n",
    "model.add(layers.InputLayer(input_shape=input_shape))\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second Conv Layer (64 filters, 3x3 kernel, ReLU activation)\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Third Conv Layer (64 filters, 3x3 kernel, ReLU activation)\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output and add Dense layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# First Fully Connected Layer (512 units, ReLU activation)\n",
    "model.add(layers.Dense(units=512, activation='relu'))\n",
    "\n",
    "# Output Layer (10 units for 10 classes, Softmax activation)\n",
    "model.add(layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32c9643",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ab6d9",
   "metadata": {},
   "source": [
    "## Compile the Model\n",
    "\n",
    "Compile the model by specifying the optimiser type and loss function and any additional metrics we would like to record during training.\n",
    "\n",
    "- Optimiser: **RMSProp**\n",
    "- loss: **Categorical Cross-entropy**\n",
    "- metrics: **Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc199be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=TrainingConfig.LEARNING_RATE),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9c8f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=TrainingConfig.BATCH_SIZE,\n",
    "    epochs=TrainingConfig.EPOCHS,\n",
    "    validation_split=TrainingConfig.VALIDATION_SPLIT,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c2f5c",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193ea86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model using the sequential API\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model2 = models.Sequential()\n",
    "\n",
    "\n",
    "\n",
    "# First Conv Layer (32 filters, 3x3 kernel, ReLU activation, input shape)\n",
    "input_shape=(32, 32, 3)\n",
    "model2.add(layers.InputLayer(input_shape=input_shape))\n",
    "model2.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model2.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(layers.Dropout(0.25))\n",
    "\n",
    "# Second Conv Layer (64 filters, 3x3 kernel, ReLU activation)\n",
    "model2.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model2.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "# Third Conv Layer (64 filters, 3x3 kernel, ReLU activation)\n",
    "model2.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model2.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(layers.Dropout(0.25))\n",
    "\n",
    "# Flatten the output and add Dense layers\n",
    "model2.add(layers.Flatten())\n",
    "\n",
    "# First Fully Connected Layer (512 units, ReLU activation)\n",
    "model2.add(layers.Dense(units=512, activation='relu'))\n",
    "model2.add(layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "# Output Layer (10 units for 10 classes, Softmax activation)\n",
    "model2.add(layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2977b",
   "metadata": {},
   "source": [
    "## Compile the Model Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5580cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=TrainingConfig.BATCH_SIZE,\n",
    "    epochs=TrainingConfig.EPOCHS,\n",
    "    validation_split=TrainingConfig.VALIDATION_SPLIT,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccccfb96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
