{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla MobileNetV3 Implementation\n",
    "\n",
    "**AIM: Build and train an image classifier to detect images from different animal species using a Custom MobileNet Model in TensorFlow.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "- Data visualisation\n",
    "- Data preprocessing and image augmentation\n",
    "- Replicate the MobileNetV3 architecture for model development.\n",
    "- Compile and train the model\n",
    "- Add early stopping callback\n",
    "- Save and load the model\n",
    "- Model evaluation.\n",
    "- Make predictions on new data using the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisite\n",
    "- Google collaboratry or Jupyter Notebook\n",
    "- animal-image-classification-dataset\n",
    "- TensorFlow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-15 11:10:51.068170: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1771150251.147313    8678 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1771150251.169060    8678 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1771150251.324589    8678 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771150251.324610    8678 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771150251.324611    8678 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771150251.324613    8678 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-02-15 11:10:51.343111: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import basic libraries\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 15 11:10:53 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.126.09             Driver Version: 580.126.09     CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Quadro RTX 4000                Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   46C    P8              6W /  110W |       6MiB /   8192MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2965      G   /usr/lib/xorg/Xorg                        4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus= tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1771150254.392470    8678 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6624 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n",
       " LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logical_devices = tf.config.list_logical_devices()\n",
    "logical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version 2.19.0\n"
     ]
    }
   ],
   "source": [
    "# Check tenorflow version\n",
    "print(\"TensorFlow Version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../dataset/animal_image_classification_dataset')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set the base path\n",
    "base_dir = \"../dataset/animal_image_classification_dataset\"\n",
    "base_dir = pathlib.Path(base_dir)\n",
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../dataset/animal_image_classification_dataset/Training Data/Training Data')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train directory\n",
    "train_dir = base_dir / \"Training Data\" / \"Training Data\"\n",
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../dataset/animal_image_classification_dataset/Validation Data/Validation Data')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation directory\n",
    "validation_dir = base_dir / \"Validation Data\" / \"Validation Data\"\n",
    "validation_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set Hyperparameters\n",
    "\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = 128, 128\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/animal_image_classification_dataset/Training Data/Training Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the training dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[1;32m      4\u001b[0m     train_dir,\n\u001b[1;32m      5\u001b[0m     image_size\u001b[38;5;241m=\u001b[39m(IMAGE_HEIGHT, IMAGE_WIDTH),\n\u001b[1;32m      6\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m      7\u001b[0m     seed\u001b[38;5;241m=\u001b[39mSEED,\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/image_dataset_utils.py:265\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, format, verbose)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[0;32m--> 265\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m dataset_utils\u001b[38;5;241m.\u001b[39mindex_directory(\n\u001b[1;32m    266\u001b[0m     directory,\n\u001b[1;32m    267\u001b[0m     labels,\n\u001b[1;32m    268\u001b[0m     formats\u001b[38;5;241m=\u001b[39mALLOWLIST_FORMATS,\n\u001b[1;32m    269\u001b[0m     class_names\u001b[38;5;241m=\u001b[39mclass_names,\n\u001b[1;32m    270\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m    271\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[1;32m    272\u001b[0m     follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[1;32m    273\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    274\u001b[0m )\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/dataset_utils.py:743\u001b[0m, in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    742\u001b[0m     subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 743\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os_module\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[1;32m    744\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m path_module\u001b[38;5;241m.\u001b[39misdir(path_module\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    745\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/animal_image_classification_dataset/Training Data/Training Data'"
     ]
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation dataset\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class names\n",
    "class_names = train_dataset.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of classes\n",
    "num_classes = len(class_names)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "for images, labels in train_dataset.take(1):\n",
    "    fixed_images = images.numpy()\n",
    "    fixed_labels = labels.numpy()\n",
    "\n",
    "\n",
    "# Visualisations\n",
    "# No matter how many times you run this cell, the images won change because of teh above\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(fixed_images[i].astype(\"uint8\"))\n",
    "    plt.title(class_names[fixed_labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla MobileNetV3 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH) + (3, )\n",
    "INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=INPUT_SHAPE)\n",
    "\n",
    "# STEM CONVOLUTION (Initial Layer)\n",
    "x = tf.keras.layers.Conv2D(filters=32,\n",
    "                                kernel_size=(3, 3),\n",
    "                                strides=2,\n",
    "                                padding=\"same\",\n",
    "                                use_bias=False)(inputs)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "# BLOCK 1 (Expansion = 1)\n",
    "block_input = x\n",
    "\n",
    "x = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3),\n",
    "                                    strides=1,\n",
    "                                    padding=\"same\",\n",
    "                                    use_bias=False)(block_input)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=16,\n",
    "                           kernel_size=1,\n",
    "                           padding=\"same\",\n",
    "                           use_bias=False)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "# NOTE: No residual here because channel mismatch\n",
    "\n",
    "\n",
    "# BLOCK 2 (Expansion = 6, Stride = 2)\n",
    "block_input = x\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=16*6,\n",
    "                           kernel_size=(1, 1),\n",
    "                           padding=\"same\",\n",
    "                           use_bias=False)(block_input)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "x = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3),\n",
    "                                    strides=2,\n",
    "                                    padding=\"same\",\n",
    "                                    use_bias=False)(block_input)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=24,\n",
    "                           kernel_size=1,\n",
    "                           padding=\"same\",\n",
    "                           use_bias=False)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "\n",
    "# BLOCK 3 (Expansion = 6, Stride = 1, Residual)\n",
    "block_input = x\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=24*6,\n",
    "                           kernel_size=(1, 1),\n",
    "                           padding=\"same\",\n",
    "                           use_bias=False)(block_input)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "x = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3),\n",
    "                                    strides=1,\n",
    "                                    padding=\"same\",\n",
    "                                    use_bias=False)(block_input)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=24,\n",
    "                           kernel_size=1,\n",
    "                           padding=\"same\",\n",
    "                           use_bias=False)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Add()([block_input, x])\n",
    "\n",
    "\n",
    "# BLOCK 4 (Expansion = 6, Stride = 2)\n",
    "block_input = x\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=24*6,\n",
    "                           kernel_size=(1, 1),\n",
    "                           padding=\"same\",\n",
    "                           use_bias=False)(block_input)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "x = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3),\n",
    "                                    strides=2,\n",
    "                                    padding=\"same\",\n",
    "                                    use_bias=False)(block_input)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=32,\n",
    "                           kernel_size=1,\n",
    "                           padding=\"same\",\n",
    "                           use_bias=False)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "\n",
    "# BLOCK 5 (Expansion = 6, Residual)\n",
    "block_input = x\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=32*6,\n",
    "                           kernel_size=(1, 1),\n",
    "                           padding=\"same\",\n",
    "                           use_bias=False)(block_input)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "x = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3),\n",
    "                                    strides=1,\n",
    "                                    padding=\"same\",\n",
    "                                    use_bias=False)(block_input)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=32,\n",
    "                           kernel_size=1,\n",
    "                           padding=\"same\",\n",
    "                           use_bias=False)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Add()([block_input, x])\n",
    "\n",
    "\n",
    "# Final Conv Layer\n",
    "x = tf.keras.layers.Conv2D(filters=1280,\n",
    "                           kernel_size=1,\n",
    "                           padding=\"same\",\n",
    "                           use_bias=False)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU(max_value=6)(x)\n",
    "\n",
    "\n",
    "# Classification Head\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    loss=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Callbacks\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"models/vanilla_mobilenet_model.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_learning_rate = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    factor=0.3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [model_checkpoint, early_stopping, reduce_learning_rate]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model to learn patterns from the image\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=validation_dataset,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(18, 7))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "    plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
    "    plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(validation_dataset)\n",
    "\n",
    "print(f\"Model Loss: {loss:.2f}\")\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2610296,
     "sourceId": 4894244,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
